# ğŸ§  AI Text Summarizer ğŸ“  

[![Python](https://img.shields.io/badge/Python-3.10%2B-blue?logo=python&logoColor=white)](https://www.python.org/)
[![LangChain](https://img.shields.io/badge/LangChain-Framework-green?logo=chainlink&logoColor=white)](https://python.langchain.com/)
[![HuggingFace](https://img.shields.io/badge/Hugging%20Face-ğŸ¤—-yellow?logo=huggingface&logoColor=white)](https://huggingface.co/)
[![License: MIT](https://img.shields.io/badge/License-MIT-purple.svg)](LICENSE)
[![Build](https://img.shields.io/badge/Build-Passing-brightgreen)](https://github.com/TawficaBhuiyan/ai-text-summarizer/actions)

---

A **Python-based AI text summarizer** powered by **LangChain** and **Large Language Models (LLMs)** â€” built to efficiently summarize both short and long texts.  

This project demonstrates how to build an **offline or cloud-connected summarizer** using Hugging Face and LangChain â€” a great starting point for LLM-based applications.  

---

## ğŸŒŸ Features  

- âœ¨ Summarizes text into concise bullet points  
- ğŸ§© Supports short & long documents via automatic chunking  
- âš™ï¸ Works fully **offline** using `facebook/bart-large-cnn`  
- â˜ï¸ Optional **cloud API** (Hugging Face Hub integration)  
- ğŸ’» **CLI-friendly** â€” summarize raw text or text files directly  
- âœ… Includes **unit tests** for summarizer verification  

---

## ğŸ’¡ What Are LLMs & LangChain?  

**Large Language Models (LLMs)** â€” AI models like *GPT-4*, *BART*, and *T5* trained to understand and generate human-like text.  
They can summarize, answer questions, translate, or generate coherent text.  

**LangChain** â€” a Python library that structures LLM workflows through **chains**, **prompt templates**, and **memory**.  
Here, itâ€™s used to **chunk**, **summarize**, and **combine** text efficiently.  

---


## ğŸ—‚ï¸ Project Structure
```text
ğŸ“¦ ai-text-summarizer/
â”œâ”€â”€ ğŸ“‚ src/
â”‚   â”œâ”€â”€ ğŸ§  main.py       â†’ CLI entrypoint
â”‚   â”œâ”€â”€ âœ‚ï¸ summarizer.py â†’ Summarization logic
â”‚   â””â”€â”€ ğŸ§© utils.py      â†’ Text chunking utilities
â”œâ”€â”€ ğŸ§ª tests/
â”‚   â””â”€â”€ test_summarizer.py â†’ Unit tests
â”œâ”€â”€ ğŸ“¸ docs/
â”‚   â””â”€â”€ screenshots/    â†’ README images
â”œâ”€â”€ âš™ï¸ .env.example      â†’ Environment template
â”œâ”€â”€ ğŸ“œ requirements.txt  â†’ Dependencies
â”œâ”€â”€ ğŸ™ˆ .gitignore
â””â”€â”€ ğŸ“˜ README.md

âš™ï¸ Installation
1ï¸âƒ£ Clone the Repository
git clone https://github.com/TawficaBhuiyan/ai-text-summarizer.git
cd ai-text-summarizer

2ï¸âƒ£ Create & Activate a Virtual Environment

PowerShell

python -m venv .venv
.venv\Scripts\Activate.ps1


CMD

python -m venv .venv
.venv\Scripts\activate

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

ğŸ” Environment Variables
USE_LOCAL_MODEL=true
# Optional Hugging Face API:
HUGGINGFACEHUB_API_TOKEN=hf_your_token_here

ğŸš€ Usage
# Summarize raw text
python -m src.main --text "Python is versatile for AI & web development."

# Summarize a text file
python -m src.main --file sample.txt

âš™ï¸ CLI Options
| Option           | Description                     |
| ---------------- | ------------------------------- |
| `--text` or `-t` | Summarize raw text input        |
| `--file` or `-f` | Summarize from a text file path |



ğŸ§ª Testing
python -m pytest -q

ğŸ“¸ Screenshots
ğŸ§  Raw Text Summarization
<p align="center"> <img src="docs/screenshots/summarizer_output.png" alt="Summarizer Output" width="600"/> <br> <i>Example: Summarized output from terminal</i> </p> <p align="center"> <img src="docs/screenshots/testpassed.png" alt="Tests Passed" width="600"/> <br> <i>Example: All tests passed successfully</i> </p>

ğŸ¤ Contributing
# Fork the repo & create branch
git checkout -b feature/your-feature
# Commit changes
git commit -m "Add feature"
# Push & open PR
git push origin feature/your-feature


Guidelines: Follow PEP 8, add tests, update docs if needed.

ğŸ“Œ Notes

â¬ First run downloads the model (~1.6 GB)

ğŸ’» Works perfectly on CPU; GPU optional

ğŸ”’ Local summarization is fully offline (no billing or API calls)

ğŸ“š References

LangChain Documentation

Hugging Face Transformers

LLMs Explained

âš¡ License

MIT License Â© 2025 Tawfica Bhuiyan

