ğŸ§  AI Text Summarizer ğŸ“

A Python-based AI text summarizer powered by LangChain and Large Language Models (LLMs) â€” built to efficiently summarize both short and long text.

This project demonstrates how to build an offline or cloud-connected summarizer using Hugging Face and LangChain, making it a great starting point for LLM-based applications.

ğŸŒŸ Features

âœ¨ Summarizes text into concise bullet points

ğŸ§© Supports short & long documents via automatic chunking

âš™ï¸ Works fully offline using facebook/bart-large-cnn

â˜ï¸ Optional cloud API (Hugging Face Hub integration)

ğŸ’» CLI-friendly â€” summarize raw text or text files directly

âœ… Includes unit tests for summarizer verification

ğŸ’¡ What Are LLMs & LangChain?

Large Language Models (LLMs) â€” AI models like GPT-4, BART, and T5 trained to understand and generate human-like text.
They can summarize, answer questions, translate, or generate coherent text.

LangChain â€” a Python library that helps structure LLM workflows through chains, prompt templates, and memory.
Here, itâ€™s used to chunk, summarize, and combine text efficiently.

ğŸ“ Project Structure
ai-text-summarizer/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py              # CLI entrypoint
â”‚   â”œâ”€â”€ summarizer.py        # Summarization logic
â”‚   â””â”€â”€ utils.py             # Text chunking utility
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_summarizer.py   # Unit tests
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ screenshots/         # Screenshots for README
â”‚
â”œâ”€â”€ .env.example             # Environment template
â”œâ”€â”€ requirements.txt         # Dependencies
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

âš™ï¸ Installation
ğŸ§© Clone the repository
git clone https://github.com/TawficaBhuiyan/ai-text-summarizer.git
cd ai-text-summarizer

ğŸ§± Create & activate a virtual environment

PowerShell

python -m venv .venv
.venv\Scripts\Activate.ps1


CMD

python -m venv .venv
.venv\Scripts\activate

ğŸ“¦ Install dependencies
pip install -r requirements.txt

ğŸ” Configure environment variables

Create a .env file in the project root:

USE_LOCAL_MODEL=true


Optional (for Hugging Face cloud API):

HUGGINGFACEHUB_API_TOKEN=hf_your_token_here

ğŸš€ Usage
ğŸ“ 1ï¸âƒ£ Summarize raw text
python -m src.main --text "Python is a versatile language used for AI and web development."

ğŸ“„ 2ï¸âƒ£ Summarize text file
python -m src.main --file sample.txt

âš™ï¸ 3ï¸âƒ£ CLI Options
Option	Description
--text or -t	Raw text input to summarize
--file or -f	Path to a text file to summarize
ğŸ§ª Testing

Run tests using pytest:

python -m pytest -q


Verifies that summarization works for short and long inputs using the local model.

ğŸ“¸ Screenshots
ğŸ§  Raw Text Summarization
<p align="center"> <img src="docs/screenshots/summarizer_output.png" alt="Summarizer Output" width="600"/> <br> <i>Example: Summarized output from terminal</i> </p>

(Add more screenshots to docs/screenshots/ and update here as needed.)

ğŸ“Œ Notes

â¬ The first run downloads the model (~1.6 GB)

ğŸ’» Works perfectly on CPU; GPU optional

ğŸ”’ Local summarization is fully offline (no billing or API calls)

ğŸ“š References

LangChain Documentation

Hugging Face Transformers

LLMs Explained

âš¡ License

MIT License Â© 2025 Tawfica Bhuiyan
